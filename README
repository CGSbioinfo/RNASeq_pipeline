cgs-rnaseq v02
This second version will be adapted and tested for the cluster.
##------------------------------------------------------------------------------##

Software and scripts required
Make sure the following software is installed: FastQC, Trim Galore, STAR, HTSeq, 
R, edgeR, RSeQC, Picard Tools, samtools. 

The python main script calls other scripts, make sure they are available from 
the $PATH: functions.py, analysis_info.py, organizeWorkingDirectory.py, qcReads.py, 
trimmingReads.py, fastqc_tables_and_plots.py, mappingReads.py, mappingQC.py, mapping_summary.R, 
mapping_distribution.R, junctionPlotAll.R, countingReads.py, countsLog_rnaseq.R.

##------------------------------------------------------------------------------##

# Download and Install
----------------------
 $ git clone https://github.com/CGSbioinfo/RNASeq_pipeline.git

 $ cd RNASeq_pipeline/scripts
 $ for i in $(ls *); do cp $i /usr/local/bin; done # NEED SUDO!!
 $ for i in $(ls *); do chmod 777 /usr/local/bin/$i; done # NEED SUDO!

##------------------------------------------------------------------------------##
##------------------------------------------------------------------------------##


# Converting bcl to fastq and creating working folder
-----------------------------------------------------

1. The first step is to create a sample sheet using Ilumina Experiment Manager. An example of this sample
sheet is NGS_J_Wang_40026B.csv. You can find the index sequences in basespace.

2. Run the bcl2fastq script in the run folder
  $ nohup bcl2fastq --sample-sheet NGS_J_Wang_40026B.csv --no-lane-splitting

3. Create a folder with the name of the project in cgs-fs3/Sequencing/Analysis
  $ mkdir NGS-J.Wang-40026B

4. Change directory to the folder just created, which is now the working directory of the pipeline
  $ cd /mnt/cgs-fs3/Sequencing/Analysis/NGS-J.Wang-40026B/

5. Create a reads/ folder and move the reads created with bcl2fastq to this folder
  $ mkdir reads/
  $ mv /mnt/cgs-fs3/Sequencing/NextSeq_Output/160601_NS500125_0267_AH53GHBGXY/ reads/

Optional: 
If the project had two or more runs and the aim is to merge the fastq files, you can use parallel.

Example: 
ls NGS_J_Wang_40026B/* | sed 's/.*\///g' | sed 's/_R.*//g' | uniq |  parallel -j 4 --no-notice "cat NGS_J_Wang_40026B/{}_R1_001.fastq.gz NGS_J_Wang_40026B_2/{}_R1_001.fastq.gz > {}_R1_001.fastq.gz"
ls NGS_J_Wang_40026B/* | sed 's/.*\///g' | sed 's/_R.*//g' | uniq |  parallel -j 4 --no-notice "cat NGS_J_Wang_40026B/{}_R2_001.fastq.gz NGS_J_Wang_40026B_2/{}_R2_001.fastq.gz > {}_R2_001.fastq.gz"

In any case, the fastq.gz files should be saved in the reads/ folder created in step 5, which is a subdirectory from the main working directory created in step 4. 


##------------------------------------------------------------------------------##
##------------------------------------------------------------------------------##


# Running the pipeline
----------------------
Important note: All the main python scripts have a help page, so if unsure on how to use it or require information about default and additional arguments, check. For example:
  $ analysis_info.py -h 

Setting up the analysis
-----------------------
1. Go to the main folder of the project and run:
  $ analysis_info.py
This will create a file named analysis_info.txt, which needs to be filled in a text editor. For more details about how to fill this file, see analysis_info_guide.txt

2. Create a sample_names.txt file with the list of the sample names. If your fastq files are saved in the reads/ subfolder, you can run:
  $ ls reads/*fastq.gz | sed 's/.*\///g' | sed 's/_R.*//g' | uniq > sample_names.txt
The names of the samples normally consist of sampleX_S1, sampleY_S2, etc.  

3. Next run:
  $ organizeWorkingDirectory.py --analysis_info_file analysis_info.txt

QC and trimming
---------------
Run the following commands:
  $ qcReads.py --in_dir rawReads/ --out_dir rawReads/

  $ fastqc_tables_and_plots.py --in_dir rawReads/ --out_dir rawReads/ --suffix_name _raw --out_dir_report Report/figure/rawQC --readType pairedEnd  

  $ trimmingReads.py --in_dir rawReads/ --out_dir trimmedReads/ --ncores 9

  $ fastqc_tables_and_plots.py --in_dir trimmedReads/ --out_dir trimmedReads/ --suffix_name _trimmed --out_dir_report Report/figure/trimmedQC --readType pairedEnd

Mapping and mapping QC
----------------------
Run the following commands:
  $ mappingReads.py --in_dir trimmedReads/ --out_dir alignedReads/
**We have observed that the mapping takes a long time when not run locally. You can run STAR locally by adding the argument --temp_dir <whatever_local_dir>. This will create a temp local folder as specifyied and run STAR. When the mapping is finished it will automatically move the results to the original working directory.

  $ mappingQC.py --in_dir alignedReads/ --out_dir alignedReads/QC/ 

Counting Reads
--------------
Run the following commands:
  $ countingReads.py --in_dir countedReads/ --out_dir countedReads/


Differential expression
-----------------------
This section is currently done using edgeR. 
DESeq2 is used only to do a PCA using rlog values. 

There are 4 files needed:
1. deseq2_arguments.txt
2. edger_arguments.txt
3. sample_info.txt
4. comparisons.csv

To create these files run:
  $ differential_expression.py --deseq2_arguments deseq2_arguments.txt --edger_arguments edger_arguments.txt --sample_info sample_info.txt --comparisons comparisons.csv

Then, fill the files with the corresponding information. 

Next, create the PCA using DESeq2:
 $ Rscript /usr/local/bin/deseq2.R deseq2_arguments.txt

Next, run edgeR:
 $ Rscript /usr/local/bin/edger.R edger_arguments.txt

The output of the above scripts will be wherever it was indicated in the *_arguments file. 

If you want to change the arguments, like paired/non-paired design, or test a different min counts to filter genes, you can create a second arguments file with a different name to keep record of both:
  $ differential_expression.py --edger_arguments edger_arguments_paired.txt



